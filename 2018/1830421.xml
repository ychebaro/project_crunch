<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NRI: FND: Robust Inverse Learning for Human-Robot Collaboration</AwardTitle>
<AwardEffectiveDate>09/01/2018</AwardEffectiveDate>
<AwardExpirationDate>08/31/2021</AwardExpirationDate>
<AwardAmount>644182</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>James Donlon</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Collaborative robots are robots that share with humans their work and personal spaces. These robots are expected to work with humans on a variety of tasks in various situations with few changes to their software and hardware. To do this, the robot must understand what is it that the human or other robot is doing, how is the human or robot performing the task, and then personalize its interaction. Currently, robots are programmed with much manual effort to perform specific tasks in controlled environments. This research is studying ways that will substantially advance a robot's capabilities in all these aspects, to enable a collaboration that is as automatic and seamless as possible. It is building methods, which allow the robot to observe the human or robot perform the task, understand the human's preferences and intent in the task, and then spontaneously collaborate with the human on the task. This approach relies on the insight that observing a human or robot perform the task provides information and facilitates learning the task. An application considered in this project is an agricultural robot that will observe and autonomously collaborate with a human in grading and packing onions in postharvest processing sheds. This has the potential to augment scarce human labor in our nation's farms in performing this repetitive task. &lt;br/&gt;&lt;br/&gt;Inverse reinforcement learning (IRL) refers to both the problem and method by which an agent learns the goals and preferences of another agent that explain the latter's observed behavior. The technical approach to this research is first identifying the challenges that IRL is facing in its use toward inferring the goals and preferences of the observed agent, human or robot, in real-world contexts. The research is tractably generalizing IRL to meet key unmet challenges. It is developing new methods that will make IRL robust to real-world uncertainties involving hidden variables, occlusions, and imperfect observations by the robot. Typically, IRL is one sided and the reward is learned with the aim of imitating the observed behavior. This research will go a step further and investigate how the dynamics and learned preferences can be revised and incorporated in the robot's collaborative decision making and planning, to enable the robot to spontaneously collaborate with the previously observed agent on the task. Consequently, the focus is on domains where the subject robot can observe an agent performing well-defined tasks that benefit from teamwork. The research plan is expected to yield a portfolio of algorithms that take key steps toward enabling robots to autonomously learn how to perform tasks and deploy this knowledge toward optimally collaborating with others on the task. Being able to learn tasks simply from passive demonstrations provides greater appeal to this research as it minimizes costly human interventions.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/18/2018</MinAmdLetterDate>
<MaxAmdLetterDate>08/18/2018</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1830421</AwardID>
<Investigator>
<FirstName>Prashant</FirstName>
<LastName>Doshi</LastName>
<EmailAddress>pdoshi@cs.uga.edu</EmailAddress>
<StartDate>08/18/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Yi</FirstName>
<LastName>Hong</LastName>
<EmailAddress>yi.hong@uga.edu</EmailAddress>
<StartDate>08/18/2018</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Kenneth</FirstName>
<LastName>Bogert</LastName>
<EmailAddress>kbogert@unca.edu</EmailAddress>
<StartDate>08/18/2018</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Georgia Research Foundation Inc</Name>
<CityName>ATHENS</CityName>
<ZipCode>306021589</ZipCode>
<PhoneNumber>7065425939</PhoneNumber>
<StreetAddress>310 East Campus Rd</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
</Institution>
<ProgramElement>
<Code>8013</Code>
<Text>National Robotics Initiative</Text>
</ProgramElement>
<ProgramReference>
<Code>063Z</Code>
<Text>W-HTF Work at the Human-Technology Front</Text>
</ProgramReference>
<ProgramReference>
<Code>8086</Code>
<Text>Natl Robotics Initiative (NRI)</Text>
</ProgramReference>
</Award>
</rootTag>
