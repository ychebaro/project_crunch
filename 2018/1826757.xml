<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CompCog: Advancing Understanding of Visual Crowding</AwardTitle>
<AwardEffectiveDate>09/01/2018</AwardEffectiveDate>
<AwardExpirationDate>08/31/2021</AwardExpirationDate>
<AwardAmount>689213</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Lawrence Gottlob</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Most of vision is peripheral vision. The central fovea comprises only 1.7 degrees of the visual field, leaving 99.99% of the visual input to fall on the peripheral retina. Peripheral vision differs from central vision in complex and interesting ways, most importantly due to 'crowding', in which identifying a peripheral stimulus can be substantially impaired by the presence of other, nearby stimuli. Crowding is a critical bottleneck in vision; substantial behavioral evidence demonstrates that crowding greatly limits our ability to perform most real-world visual tasks. The research team will pit a dominant class of models, known as pooling models, against a rich corpus of recent experimental work which has seemed to suggest that visual mechanisms might be more complicated and dynamic than previously thought. This work could enable development of improved materials and tools for those with age-related macular degeneration, in which patients lose central vision. It could also aid design of heads-up displays, user interfaces, and information visualizations such as situation maps for military decision-making.&lt;br/&gt;&lt;br/&gt;Pooling models posit that crowding arises from averaging of features over large local regions, fixed in size, which grow linearly with distance from the point of fixation. The PI has spent the last decade developing the computational and behavioral methodologies that allow one to derive quantitative, testable predictions from a state-of-the-art pooling model. Using these tools, the PI will examine a definitive set of crowding phenomena that have appeared to challenge a unifying account in terms of a pooling mechanism. She will take a three-pronged approach: 1) using modeling and behavioral experiments to examine the assumptions underlying the model challenges; 2) using behavioral experiments to eliminate possible confounds; and 3) designing new experiments to directly test alternative theories. The expected overall impact is to fundamentally advance mechanistic understanding of a key bottleneck in peripheral processing, and thus in visual processing more generally.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>09/06/2018</MinAmdLetterDate>
<MaxAmdLetterDate>09/06/2018</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1826757</AwardID>
<Investigator>
<FirstName>Ruth</FirstName>
<LastName>Rosenholtz</LastName>
<EmailAddress>rruth@mit.edu</EmailAddress>
<StartDate>09/06/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Massachusetts Institute of Technology</Name>
<CityName>Cambridge</CityName>
<ZipCode>021394301</ZipCode>
<PhoneNumber>6172531000</PhoneNumber>
<StreetAddress>77 MASSACHUSETTS AVE</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Massachusetts</StateName>
<StateCode>MA</StateCode>
</Institution>
<ProgramElement>
<Code>1397</Code>
<Text>CROSS-DIRECTORATE  ACTIV PROGR</Text>
</ProgramElement>
<ProgramElement>
<Code>7252</Code>
<Text>PERCEPTION, ACTION &amp; COGNITION</Text>
</ProgramElement>
<ProgramReference>
<Code>063Z</Code>
<Text>W-HTF Work at the Human-Technology Front</Text>
</ProgramReference>
<ProgramReference>
<Code>7252</Code>
<Text>Perception, Action and Cognition</Text>
</ProgramReference>
</Award>
</rootTag>
