<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>III: Small: Collaborative Research: Explainable Natural Language Inference</AwardTitle>
<AwardEffectiveDate>09/01/2018</AwardEffectiveDate>
<AwardExpirationDate>08/31/2021</AwardExpirationDate>
<AwardAmount>244537</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Maria Zemankova</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Natural language inference (NLI) can support decision-making using information contained in natural language texts (e.g, detecting undiagnosed medical conditions in medical records, finding alternate treatments from scientific literature). This requires gathering facts extracted from text and reasoning over them. Current automated solutions for NLI are largely incapable of producing explanations for their inferences, but this capacity is essential for users to trust their reasoning in domains such as scientific discovery and medicine where the cost of making errors is high. This project develops natural language inference methods that are both accurate and explainable. They are accurate because they build on state-of-the-art deep learning frameworks which use powerful, automatically learned, representations of text. They are explainable because they aggregate information in units that can be represented in both a human readable explanation and a machine-usable vector representation. This project will advance methods in explainable natural language inference to enable the application of automated inference methods in critical domains such as medical knowledge extraction. The project will also evaluate the explainability of the inference decisions in collaboration with domain experts.&lt;br/&gt;&lt;br/&gt;This project reframes natural language inference as the task of constructing and reasoning over explanations. In particular, inference assembles smaller component facts into a graph (explanation graph) that it reasons over to make decisions. In this view, generating explanations is an integral part of the inference process and not a separate post-hoc mechanism. The project has three main goals: (a) Develop multiagent reinforcement learning models that can effectively and efficiently explore the space of explanation graphs, (b) Develop deep learning based aggregation mechanisms that can prevent inference from combining semantically incompatible evidence, and (c) Build a continuum of hypergraph based text representations that combine discrete forms of structured knowledge with their continuous embedding based representations. The techniques will be evaluated on three application domains: complex question answering, medical relation extraction, and clinical event detection from medical records. The results of the project will be disseminated through the project website, scholarly venues, and the software and datasets will be made available to the public.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>07/27/2018</MinAmdLetterDate>
<MaxAmdLetterDate>07/27/2018</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1815358</AwardID>
<Investigator>
<FirstName>Niranjan</FirstName>
<LastName>Balasubramanian</LastName>
<EmailAddress>niranjan@cs.stonybrook.edu</EmailAddress>
<StartDate>07/27/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>SUNY at Stony Brook</Name>
<CityName>Stony Brook</CityName>
<ZipCode>117940001</ZipCode>
<PhoneNumber>6316329949</PhoneNumber>
<StreetAddress>WEST 5510 FRK MEL LIB</StreetAddress>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
</Institution>
<ProgramElement>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramElement>
<ProgramReference>
<Code>075Z</Code>
<Text>Artificial Intelligence (AI)</Text>
</ProgramReference>
<ProgramReference>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
</Award>
</rootTag>
