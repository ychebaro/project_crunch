<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CRII: SaTC: Moderating Effects of Automation on Information Transmission in Social Forums</AwardTitle>
<AwardEffectiveDate>06/01/2019</AwardEffectiveDate>
<AwardExpirationDate>05/31/2021</AwardExpirationDate>
<AwardTotalIntnAmount>174910.00</AwardTotalIntnAmount>
<AwardAmount>174910</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sara Kiesler</SignBlockName>
</ProgramOfficer>
<AbstractNarration>This project aims to develop and deploy an information veracity evaluation system to support online discourse moderation and human comprehension of online information.  Understanding information's nature can help users to identify essential products and services, and even potentially help to inform democratic participation.  The project will help individual users navigate an environment where the views of their online peers may be difficult to interpret, or where it may not be clear whether other users are human or covert social bots (e.g., for social engineering to obtain personal information).  The research project develops capacities for identifying social bots and evaluating their stances towards claims on forums to underpin a system that will provide automated veracity evaluation of web content and analysis to support forum moderators.  These projects will shed light on the use of social bots at affecting reader perceptions of information, bringing awareness to dangers of automation in the infosphere and ultimately, support for vigilance and anticipation of automation attacks. &lt;br/&gt;&lt;br/&gt;This project aims to produce an open-source, automated social information veracity evaluation system that can support moderation of, and ultimately, user navigation in online discourse environments.  This system will be developed with auxiliary foci on detecting social bots and evaluating social support, making it capable of filtering out covert autonomous agents while assessing their roles in the support or denial of content claims.  A veracity-annotated dataset of unprecedented size that integrates online content and associated reader commentary with social bot annotations will be extended and enriched with reader support annotations.  These will be used to develop machine learning tools that can indicate 1) users' authenticity as human commenters and 2) their stances towards claims, in order to 3) support the evaluation of their discussed content's veracity.  A platform and server-to-server applications will be built to support implementation for forum moderation, providing moderators live analytics, alerts, and an interactive visual dashboard, in addition to a public display of summarized results.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>03/04/2019</MinAmdLetterDate>
<MaxAmdLetterDate>03/04/2019</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1850014</AwardID>
<Investigator>
<FirstName>Jake</FirstName>
<LastName>Williams</LastName>
<EmailAddress>jw3477@drexel.edu</EmailAddress>
<StartDate>03/04/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Drexel University</Name>
<CityName>Philadelphia</CityName>
<ZipCode>191021119</ZipCode>
<PhoneNumber>2158955849</PhoneNumber>
<StreetAddress>1505 Race St, 10th Floor</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
</Institution>
<ProgramElement>
<Code>026Y</Code>
<Text>CRII CISE Research Initiation</Text>
</ProgramElement>
<ProgramElement>
<Code>8060</Code>
<Text>Secure &amp;Trustworthy Cyberspace</Text>
</ProgramElement>
<ProgramReference>
<Code>025Z</Code>
<Text>SaTC: Secure and Trustworthy Cyberspace</Text>
</ProgramReference>
<ProgramReference>
<Code>065Z</Code>
<Text>Human factors for security research</Text>
</ProgramReference>
<ProgramReference>
<Code>7434</Code>
<Text>CNCI</Text>
</ProgramReference>
<ProgramReference>
<Code>8228</Code>
<Text>CISE Resrch Initiatn Initiatve</Text>
</ProgramReference>
</Award>
</rootTag>
