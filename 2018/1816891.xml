<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small:Comp Cog: Broad-coverage semantic models of human sentence processing</AwardTitle>
<AwardEffectiveDate>08/15/2018</AwardEffectiveDate>
<AwardExpirationDate>07/31/2021</AwardExpirationDate>
<AwardAmount>490287</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Donald T. Langendoen</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Humans are a successful species in large part because they can pass knowledge about the world to one another using linguistic explanations.  These explanations can be quite complex, involving nested generalizations about multiple classes of objects and events.  Accurate models of how these relationships are decoded from natural language could further our understanding of how the brain works, and may allow non-programmer users to explain their desired products, goals and constraints to machines.  Sentence processing experiments may provide an important window into the mechanisms of idea formation in language comprehension, but the human mind is extraordinarily sensitive to the strangeness of constructed stimuli used in experimentally controlled research designs, yielding potentially confounding effects arising from unexpected words or sentence structures.  A common alternative is to use designs employing naturally-occurring stimuli with statistical controls, usually using one or more probabilistic measures of surprise during sentence processing.  Unfortunately, existing probabilistic measures of surprise are based on overly simple models of sentence processing that are not connected to the nested structure of generalizations that a linguistic explanation may describe, and thus have severe limits as predictors of these kinds of frequency effects.  This project will therefore develop a sentence processing model that decodes sentences into meanings using a human-like incremental probabilistic process.  This model will then be used to control for frequency effects in neural activation, blood oxygenation and reading time data in order to isolate effects that can be attributed to the mechanical process of constructing and storing complex ideas during language comprehension.&lt;br/&gt;&lt;br/&gt;This project constructs a model of sentence processing that bases its processing decisions on mental representations of meanings rather than on words only.  This means that the model will be less surprised by repeated nouns or pronouns when these words refer to a common entity which is prominent in a discourse.  The project initially focuses on the development of a statistical sentence processing model which maintains several possible analyses of a sentence after each word is processed, each of which contains explicit representations of each discourse referent involved in a sentence meaning as a set of logical predicates adjacent to that referent in a graphical representation of the meaning.  A subsequent version of the model compresses these context sets into vectors, which are passed through a recurrent neural network.  The predictions of these models are compared against existing neural network language models used in natural language processing applications to ensure that their linguistic predictions are accurate.  Incremental probabilities generated by these models are then used to estimate probabilistic surprise as a frequency control in predicting functional magnetic resonance (fMRI), electroencephalographic (EEG), eye-tracking, and reading-time observations in existing datasets, in order to isolate effects due to memory usage and other mechanistic factors.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/09/2018</MinAmdLetterDate>
<MaxAmdLetterDate>08/09/2018</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1816891</AwardID>
<Investigator>
<FirstName>William</FirstName>
<LastName>Schuler</LastName>
<EmailAddress>schuler.77@osu.edu</EmailAddress>
<StartDate>08/09/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Ohio State University</Name>
<CityName>Columbus</CityName>
<ZipCode>432101016</ZipCode>
<PhoneNumber>6146888735</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<StateCode>OH</StateCode>
</Institution>
<ProgramElement>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
</Award>
</rootTag>
