<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Improving Particle Filter Performance in Spatially-Extended Problems Using Generalized Random Field Likelihoods</AwardTitle>
<AwardEffectiveDate>09/01/2018</AwardEffectiveDate>
<AwardExpirationDate>08/31/2021</AwardExpirationDate>
<AwardTotalIntnAmount>219814.00</AwardTotalIntnAmount>
<AwardAmount>70728</AwardAmount>
<AwardInstrument>
<Value>Continuing grant</Value>
</AwardInstrument>
<Organization>
<Code>03040000</Code>
<Directorate>
<Abbreviation>MPS</Abbreviation>
<LongName>Direct For Mathematical &amp; Physical Scien</LongName>
</Directorate>
<Division>
<Abbreviation>DMS</Abbreviation>
<LongName>Division Of Mathematical Sciences</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Christopher Stark</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Ensembles of model simulations are used in a variety of fields to estimate and predict things like rain, plankton blooms, or oil well pressure. Ensembles are used to provide uncertainty quantification to the predictions: one wants to know not just the most likely estimate but also how likely this estimate is, and whether any other outcomes are likely. The main mathematical framework that underpins the rigorous use of ensembles for uncertainty quantitfication is called, for historical reasons, the 'particle filter.' Each ensemble member is a 'particle.' Unfortunately particle filters do not work well for problems in high dimensions -- a `dimension' can be loosely understood here as a location where observational data is available, not the dimensions of space and time -- since they require an astronomically large number of ensemble members. This project will develop methods to improve the performance of particle filters in problems with spatial extent, like weather forecasting. The improvement comes by reducing the effective dimensionality by smoothing the observations. For example, millions of satellite observations of the atmosphere and oceans are taken each day; the project reduces the dimensionality of this data in a manner qualitatively similar to compressing an image. Since the required ensemble size for a particle filter is exponentially sensitive to the effective dimension of the system, even a small compression of the data can lead to enormous improvements in the performance of the particle filter.&lt;br/&gt;&lt;br/&gt;The sequential importance sampling particle filter with resampling is known to converge, in the limit of infinite ensemble size, to the Bayesian posterior of the filtering problem for dynamical systems (under mild assumptions). Unfortunately the rate of convergence is slow: the required ensemble size is exponential in the effective dimension of the system. This is prohibitive for spatially-extended problems like weather forecasting, where the effective dimension is enormous. Alternative methods like the ensemble Kalman filters are very successful in practice, but there is no rigorous analysis relating the distribution that the ensemble members represent and the true Bayesian posterior. This project aims to improve particle filter performance by reducing the effective dimensionality of the system for spatially extended problems. The true likelihood representing the relationship between the observational data and the system state is altered by smoothing the observations. This reduces the effective dimensionality of the system and is equivalent to modeling the observation error as a generalized random field. Although the particle filter converges more rapidly, it converges to a distribution that is not the true Bayesian posterior. However, the character of the error between the true and approximate posteriors is known and can be controlled to balance accuracy and cost, unlike the ensemble Kalman filters where the difference between the ensemble distribution and the true posterior is unknown and uncontrolled. The main technical goal of the project is to develop smoothing operators that can be applied to scattered spatial data in Cartesian coordinates or on the sphere. These operators need to be computationally efficient, and to allow the degree of smoothing to be tunable. Fast methods will be developed based on radial basis function interpolation of the data, followed by the fast application of a smoothing integral operator, approximated using multi-resolution Gaussian atoms. The method will be applied to meteorological data to build intuition on how the degree of smoothing impacts the posterior. If necessary, the method will be combined with other methods for improving particle filter performance, like implicit sampling or optimal transport.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/15/2018</MinAmdLetterDate>
<MaxAmdLetterDate>08/15/2018</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1821074</AwardID>
</Award>
</rootTag>
