<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Collaborative Research: Identifying Model-Based Motor Control Strategies to Enhance Human-Machine Interaction</AwardTitle>
<AwardEffectiveDate>09/01/2018</AwardEffectiveDate>
<AwardExpirationDate>08/31/2021</AwardExpirationDate>
<AwardAmount>388996</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07030000</Code>
<Directorate>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<LongName>Div Of Civil, Mechanical, &amp; Manufact Inn</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Robert Scheidt</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Humans are increasingly asked to cooperate with machines and robots in many occupational and recreational settings, including teleoperation, driving vehicles, surgery, rehabilitation, and object manipulation. Not only must humans learn to share control with a machine, the machines must in turn be better designed to enable human-machine interaction. The main objectives of this collaborative project are: to perform fundamental research that will identify multisensory (visual and haptic), human-in-the-loop, sensorimotor control models that capture predictive and reactive aspects of how people interact with their physical environment (e.g., machines); to advance understanding of how multisensory control can degrade in a patient population with degeneration of the cerebellum, which is thought to contribute importantly to tool use; and to advance understanding of how control systems for machines can be developed to exploit identified models of human sensorimotor control to enhance performance of human-machine interactions. The project is significant because it develops computable theories (computational models of human sensorimotor control) and the physical manifestation of those theories (robotic control algorithms) that will lead to enhanced human-machine interactions. This project directly serves the NSF mission by promoting fundamental science exploring modes of interaction between humans and intelligent robotic systems, which may contribute to advancing the national health. The project supports education through outreach activities aimed at recruiting and retaining students in STEM fields.&lt;br/&gt;&lt;br/&gt;This research will contribute to a fundamental understanding of human motor behavior by developing a set of multidomain (haptic and visual) models that describe the application of model-based control strategies in the context of accommodating (or rejecting) influences from the environment.  Aim 1 builds on the assumption that the computational problem solved by the human nervous system can be captured using model-based control strategies involving a combination of predictive (feedforward) and reactive (feedback) mechanisms. In a series of four sets of experiments, the team will use single-sine "predictable" and sum-of-sines "unpredictable" disturbances of visual and haptic feedback to interrogate sensorimotor control during reaching and object manipulation tasks. By identifying the structure and parameters of neuromotor control in these tasks, the PIs set the stage for later development of engineered control systems to improve human-machine interaction.  Experiments supporting Aim 2 will mirror those serving Aim 1, identifying how sensorimotor control is impaired in a cohort of cerebellar ataxia patients. Expected results promise insight into the cerebellum's contributions to motor coordination and control, thereby advancing the national research priority of understanding brain function in health and disease.  Aim 3 seeks to engineer intelligent machine controllers to "wrap around" a human's model-based control system to enhance cooperative performance of the overall human-machine system. Cohorts of neurologically intact and cerebellar patients will be tested. One set of experiments will examine the extent to which human participants can correctly interpret haptic feedback to correctly perceive whether a coupled automaton works "for" or "against" their efforts. A second set of experiments will exploit individualized models of sensorimotor control to examine the extent to which real-time visual feedback of hand position can be augmented to enhance performance of goal-directed reaching in patients with cerebellar ataxia.  The project outcomes may have long-term impact by advancing understanding of how machine control can be designed to enhance performance of physically-coupled human-machine systems.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/20/2018</MinAmdLetterDate>
<MaxAmdLetterDate>08/20/2018</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1825931</AwardID>
<Investigator>
<FirstName>Richard</FirstName>
<LastName>Gillespie</LastName>
<EmailAddress>brentg@engin.umich.edu</EmailAddress>
<StartDate>08/20/2018</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>James</FirstName>
<LastName>Freudenberg</LastName>
<EmailAddress>jfr@umich.edu</EmailAddress>
<StartDate>08/20/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Michigan Ann Arbor</Name>
<CityName>Ann Arbor</CityName>
<ZipCode>481091274</ZipCode>
<PhoneNumber>7347636438</PhoneNumber>
<StreetAddress>3003 South State St. Room 1062</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<StateCode>MI</StateCode>
</Institution>
<ProgramElement>
<Code>004Y</Code>
<Text>Science of Learning</Text>
</ProgramElement>
<ProgramElement>
<Code>058Y</Code>
<Text>M3X - Mind, Machine, and Motor</Text>
</ProgramElement>
<ProgramReference>
<Code>059Z</Code>
<Text>Science of Learning</Text>
</ProgramReference>
<ProgramReference>
<Code>070E</Code>
<Text>INTEG OF HUMAN &amp; COGNITIVE</Text>
</ProgramReference>
<ProgramReference>
<Code>7632</Code>
<Text>HUMAN-ROBOT INTERACTION</Text>
</ProgramReference>
</Award>
</rootTag>
