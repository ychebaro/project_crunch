<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Robustness of Inductive Reasoning Engines</AwardTitle>
<AwardEffectiveDate>03/01/2019</AwardEffectiveDate>
<AwardExpirationDate>02/29/2024</AwardExpirationDate>
<AwardAmount>94990</AwardAmount>
<AwardInstrument>
<Value>Continuing grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Nina Amla</SignBlockName>
</ProgramOfficer>
<AbstractNarration>The past decade has seen a renaissance in the field of machine learning and simultaneously witnessed an explosion of interest in the related area of Programming by Example (PBE). While both fields have enjoyed spectacular successes, their algorithms can be brittle and can drive applications to unexpected failures. The cause of many failures in both machine-learning and PBE systems can be traced back to their shared task of inductive reasoning: learning some artifact in a hypothesis space from a set of examples. Since examples are inherently incomplete specifications, there can be a large number of artifacts that fit a set of examples but fail to generalize to an unseen example. This project advocates for a more principled approach to constructing such inductive reasoning engines based on a formal characterization of their reliability.&lt;br/&gt; &lt;br/&gt;The project casts the problem of reliability of these systems as one of robustness: is the change in the artifact learnt acceptable, or, at least predictable, in the presence of small changes to the set of examples? The project integrates concepts from formal methods, logic, relational reasoning, and computational learning theory to develop new foundations, algorithms and tools for the design and analysis of robust inductive reasoning engines. The multi-faceted project will impact formal methods and programming languages (through contributions to inductive synthesis and relational reasoning), machine learning (through automated techniques for addressing the dataset shift problem), and society (through users of inductive reasoning engines, and education activities targeting expansion of scientific literacy and computer science pathways). The investigator plans broad dissemination of results (through a workshop on robustness co-founded by the investigator, talks at outreach platforms and a graduate course).&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>02/01/2019</MinAmdLetterDate>
<MaxAmdLetterDate>02/01/2019</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1846327</AwardID>
<Investigator>
<FirstName>Roopsha</FirstName>
<LastName>Samanta</LastName>
<EmailAddress>roopsha@purdue.edu</EmailAddress>
<StartDate>02/01/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Purdue University</Name>
<CityName>West Lafayette</CityName>
<ZipCode>479072114</ZipCode>
<PhoneNumber>7654941055</PhoneNumber>
<StreetAddress>Young Hall</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Indiana</StateName>
<StateCode>IN</StateCode>
</Institution>
<ProgramElement>
<Code>7798</Code>
<Text>SOFTWARE &amp; HARDWARE FOUNDATION</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>8206</Code>
<Text>Formal Methods and Verification</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
</Award>
</rootTag>
