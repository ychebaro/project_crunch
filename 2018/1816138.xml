<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI:Small:Exploiting the Evolving Conditioning of Bundle Adjustment for Robust, Adaptive Simultaneous Localization and Mapping</AwardTitle>
<AwardEffectiveDate>09/01/2018</AwardEffectiveDate>
<AwardExpirationDate>08/31/2021</AwardExpirationDate>
<AwardAmount>419648</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Simultaneous localization and mapping (SLAM) is the process by which a mobile robot establishes its movement through an environment while recovering an estimate of the local environment's geometry.  It is an essential component of a mobile robot's sensory processing sub-system, especially when GPS is incorrect or unavailable. This project will develop technologies to improve the accuracy, robustness, scalability and efficiency of visual SLAM algorithms. The project will identify a means to reduce the data needs of bundle adjustment SLAM (BA-SLAM) algorithms while improving or preserving accuracy, leading to real-time SLAM methods capable of being used in the feedback loop of mobile robots.  Extending these results for point and line-based SLAM will increase the environments within which SLAM is applicable and reliable.  The project will promote exploration by undergraduate researchers and teams, and drive research in engineering fields through open source release of the code. The project will also promote engagement in engineering by diverse audiences through demonstrations using autonomous robotic activities enabled by the findings. &lt;br/&gt;&lt;br/&gt;This research will exploit the temporal conditioning properties of vision-based SLAM algorithms for assessing and improving robustness while managing computational cost. SLAM uncertainty and latency negatively impacts downstream processes when there is a feedback loop. New SLAM modifications will mitigate these issues, thereby providing more accurate and lower latency localization and mapping outputs. The theoretical foundations for the modifications will rely on observability theory, concurrent learning, and matrix theory.  Observability conditioning assesses the incoming data with regards to estimation fitness in SLAM.  Concurrent learning selectively marginalizes data over time intervals to provide a minimal connectivity inference graph for bundle adjustment.  Matrix theory suggests efficient, scalable, and nearly optimal implementations. Validation of the findings will involve existing benchmarks and new benchmarks created to test open and closed loop operation. The project generalizes to positively impact all visual SLAM algorithms designed to date through complementary data assessment and processing blocks, whose role is to lower estimation latency while improving or preserving estimation accuracy.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/13/2018</MinAmdLetterDate>
<MaxAmdLetterDate>08/13/2018</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1816138</AwardID>
<Investigator>
<FirstName>Patricio</FirstName>
<LastName>Vela</LastName>
<EmailAddress>pvela@ece.gatech.edu</EmailAddress>
<StartDate>08/13/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Georgia Tech Research Corporation</Name>
<CityName>Atlanta</CityName>
<ZipCode>303320420</ZipCode>
<PhoneNumber>4048944819</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
</Institution>
<ProgramElement>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
</Award>
</rootTag>
