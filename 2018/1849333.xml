<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>S&amp;AS:FND:Viewer-Centric Spatial Reasoning and Learning for Safe Autonomous Navigation</AwardTitle>
<AwardEffectiveDate>02/15/2019</AwardEffectiveDate>
<AwardExpirationDate>01/31/2022</AwardExpirationDate>
<AwardAmount>469997</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>James Donlon</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Autonomous navigation has emerged as one of contemporary society's most promising technological advances.  Robust, self-improving strategy for robot navigation will benefit several industries such as commercial and non-commercial transportation, large-scale infrastructure inspection, industrial warehousing, disaster response, and assistive robotics.  The main challenge to robust navigation lies in developing the ability to navigate unstructured, dynamic environments for which there may be insufficient data collected for training machine learning methods, and for which model-based reasoning is too complex. A purely learning-based strategy fails to have operational guarantees (i.e., collision avoidance is not guaranteed). The research proposes a mixed method solution whereby physics-based reasoning and machine learning work together to resolve the unstructured navigation problem. The combined approach will lead to a cognizant and reflective navigation pipeline whose performance improves with time. A central claim of this project is that the learning module will act as an efficient multi-hypothesis generator for potential navigation decisions, for which options can be processed, scored, and confirmed by the physics-based component.  The learning system will subsequently use these scores for online improvement. The net result will be mobile robots that are cognizant of their operation and adaptable to new information gained during task execution. &lt;br/&gt;&lt;br/&gt;The research goal of this proposal is to derive a safe autonomous navigation framework for general settings through the use of a viewer-centric processing paradigm capable of leveraging learning and model driven methods to overcome the limitations of entirely object-centric approaches to navigation.  Appealing to Marr's framework for visual processing, the project investigates a viewer-centric approach to navigation.  By more tightly linking perceptual and planning representations through the viewer-centric approach, the new approach leverages measurements obtained during navigation to provide online assessment for improving performance and generating knowledge regarding navigation through unknown scenes. The project investigates the effect of a viewer-centric model representation for use in local planning, as well as the connection of such representations to reflective, experiential machine learning for improved performance that leverage the model-based planning subcomponent.  The research involves meeting the following objectives: 1) Confirming the robustness of a viewer-centric navigation framework combining model-based and deep learning-based approaches for safe navigation with cognizant and adaptive operation; 2) Demonstrating enhanced reasoning through scene-selective strategies that improve through experience; and 3) Extending the framework to dynamic scenes through learned models for the relative physics of motion, whereby moving objects are modeled in the viewer's frame of reference to detect dangerous relative motion profiles.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>02/11/2019</MinAmdLetterDate>
<MaxAmdLetterDate>02/11/2019</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1849333</AwardID>
<Investigator>
<FirstName>Patricio</FirstName>
<LastName>Vela</LastName>
<EmailAddress>pvela@ece.gatech.edu</EmailAddress>
<StartDate>02/11/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Georgia Tech Research Corporation</Name>
<CityName>Atlanta</CityName>
<ZipCode>303320420</ZipCode>
<PhoneNumber>4048944819</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Georgia</StateName>
<StateCode>GA</StateCode>
</Institution>
<ProgramElement>
<Code>039Y</Code>
<Text>S&amp;AS - Smart &amp; Autonomous Syst</Text>
</ProgramElement>
<ProgramReference>
<Code>046Z</Code>
<Text>S&amp;AS - Smart &amp; Autonomous Systems</Text>
</ProgramReference>
</Award>
</rootTag>
