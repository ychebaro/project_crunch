<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>A Remote Multimodal Learning Environment to Increase Graphical Information Access for Blind and Visually Impaired Students</AwardTitle>
<AwardEffectiveDate>08/15/2018</AwardEffectiveDate>
<AwardExpirationDate>07/31/2021</AwardExpirationDate>
<AwardTotalIntnAmount>747894.00</AwardTotalIntnAmount>
<AwardAmount>747894</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Chia Shen</SignBlockName>
</ProgramOfficer>
<AbstractNarration>There are many limitations for students who are blind or visually impaired (BVI) in accessing complex STEM graphical information in the classroom or workplace. This longstanding problem arises due to reliance on inaccessible and outdated learning materials, the need for costly specialized devices, and an adherence to an outdated educational service model. To address these issues, this project will investigate the development and evaluation of an innovative remote learning system based on the use of multiple sensory channels to strategically present information from auditory, linguistic, touch, and enhanced visual sensing. The research will focus specifically on the optimization of multimodal information presentation and perception, separating sensory output based on its unique information processing characteristics for conveying different types of stimuli. The first project goal is to increase the quality of STEM instruction for BVI students by determining perceptually motivated learning supports that promote non-visual knowledge acquisition of STEM graphical and spatial information (learning goal). The second project goal is to increase access to graphical and spatial STEM content through creation of an innovative remote multimodal interface for communicating the conceptual meaning of visual information (technology goal). The project outcomes will contribute to theories of non-visual learning and multisensory processing, and a clear translational path to development of more efficient, intuitive, and usable multimodal interfaces for both blind and sighted users. The application of the results will help to address the severe under-representation of BVI individuals in STEM-related disciplines, and the 70% unemployment rate of this demographic, by providing a new, low-cost, and accessible technology platform for communicating non-visual graphical STEM materials. &lt;br/&gt;&lt;br/&gt;The researchers will answer the following inter-connected questions: 1) What is the best information content to be conveyed by different modal outputs for maximizing perceptual saliency, learnability, interpretation, and representation of STEM graphical materials? Once optimized in the lab, 2) How well does the optimized multimodal learning system perform in a remote deployment environment in conveying graphical STEM materials to BVI learners; and 3) Does the remote learning system increase the level of comprehension of STEM graphical content as compared to traditional BVI instructional methods? Both quantitative and qualitative data about the optimization process and the remote technology system will be collected and analyzed including user response metrics on speed/accuracy, user experience data, and STEM graphical assessment instruments adapted for BVI students. The first phase of the research will investigate multimodal information processing in order to establish best practices for information delivery and non-visual graphical learning efficiency with experiments comparing graphical information presented in different modalities for three core STEM graphical themes: graphs, diagrams, and maps. The second phase of experiments will investigate the remote learning system's efficacy as well as evaluating user performance on graphical STEM learning measures and key usability and satisfaction metrics. This project has the broader goals of increasing independence for BVI learners and other students with or without disabilities who might benefit from a remote multimodal learning environment, and the development of a new tool for supporting large-scale research and assistive technology evaluation with BVI human subjects, thereby dramatically increasing scientists' ability to recruit and work with a much larger population of BVI users than is currently possible from lab-based studies.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/16/2018</MinAmdLetterDate>
<MaxAmdLetterDate>02/15/2019</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1822800</AwardID>
<Investigator>
<FirstName>Nicholas</FirstName>
<LastName>Giudice</LastName>
<EmailAddress>nicholas.giudice@maine.edu</EmailAddress>
<StartDate>08/16/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Justin</FirstName>
<LastName>Dimmel</LastName>
<EmailAddress>justin.dimmel@maine.edu</EmailAddress>
<StartDate>08/16/2018</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Stacy</FirstName>
<LastName>Doore</LastName>
<EmailAddress>sdoore@bowdoin.edu</EmailAddress>
<StartDate>08/16/2018</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Maine</Name>
<CityName>ORONO</CityName>
<ZipCode>044695717</ZipCode>
<PhoneNumber>2075811484</PhoneNumber>
<StreetAddress>5717 Corbett Hall</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Maine</StateName>
<StateCode>ME</StateCode>
</Institution>
<ProgramElement>
<Code>7980</Code>
<Text>Core R&amp;D Programs</Text>
</ProgramElement>
<ProgramReference>
<Code>063Z</Code>
<Text>W-HTF Work at the Human-Technology Front</Text>
</ProgramReference>
<ProgramReference>
<Code>1545</Code>
<Text>RES IN DISABILITIES ED</Text>
</ProgramReference>
<ProgramReference>
<Code>8045</Code>
<Text>Cyberlearn &amp; Future Learn Tech</Text>
</ProgramReference>
<ProgramReference>
<Code>8212</Code>
<Text>Broaden Particip STEM Resrch</Text>
</ProgramReference>
<ProgramReference>
<Code>8817</Code>
<Text>STEM Learning &amp; Learning Environments</Text>
</ProgramReference>
<ProgramReference>
<Code>9150</Code>
<Text>EXP PROG TO STIM COMP RES</Text>
</ProgramReference>
</Award>
</rootTag>
