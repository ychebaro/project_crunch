<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CHS: Small: Deep Integration of Crowds and AI for Robust, Scalable, and Privacy-Preserving Conversational Assistance</AwardTitle>
<AwardEffectiveDate>08/15/2018</AwardEffectiveDate>
<AwardExpirationDate>07/31/2021</AwardExpirationDate>
<AwardAmount>500000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>William Bainbridge</SignBlockName>
</ProgramOfficer>
<AbstractNarration>This research will use the recently deployed crowd-powered conversational assistant, Chorus, as a scaffold to develop technical components that allow it to automate itself over time. Chorus introduces a hybrid intelligence model in which humans and machines collaboratively power a single intelligent system. This is unlike both fully-automated approaches which are limited in terms of the domains they cover, and individual human-based conversational support which does not scale.  Conversation is interactive communication. When people converse with one another, they build and refine a shared context that makes finding and making sense of information efficient and more effective. Computers capable of engaging users in natural conversations about arbitrary topics would revolutionize how, when, and where people have access to information. Despite many successes, computers are still far from being able to converse naturally across general domains. Systems resulting from this research will be robust enough and scalable enough to be used in real world domains. These types of hybrid systems may lead to new, generally applicable models that are useful in real-time human computation and natural language understanding. This work will inform a better understanding of how automated agents can learn from crowd-powered systems in order to gradually assume more responsibility over time.&lt;br/&gt;&lt;br/&gt;Creating a robust, general-purpose dialog system from the bottom up is difficult because it requires solving multiple hard problems at once. This project employs a complementary top-down approach that will (1) use the growing Chorus data set to train automatic responders, (2) facilitate integration of existing task-specific dialog systems, (3) develop learning systems to sample among integrated dialog systems and choose the best to respond, (4) develop learning systems to choose the best responses from among automated and human suggestions, (5) develop learning systems able to recommend relevant elements from the user's history based on context, (6) develop crowd-powered systems for allowing users to safely control their devices, and (7) develop crowd-powered systems that allow users to safely access private repositories such as their email. Integral to this work is the interplay between computers and people.  Central goals are to better understand how computers and people can complement the work of one another; learn how people can teach computers to be better in the difficult domain of robust dialog, and develop novel approaches for applying human computation when the crowd is handling confidential information or has control of a physical device such as a user's mobile phone. Lessons learned from exploring the top-down approach of introducing a crowd-powered conversational agent that is gradually replaced by automation may apply generally to other hard problems. This approach may allow research topics to be explored before successful computational approaches have been developed for foundational problems, such as learning how to properly curate persistent memory before having the ability to create reliable conversational assistants.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/02/2018</MinAmdLetterDate>
<MaxAmdLetterDate>08/02/2018</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1816012</AwardID>
<Investigator>
<FirstName>Jeffrey</FirstName>
<LastName>Bigham</LastName>
<EmailAddress>jbigham@cmu.edu</EmailAddress>
<StartDate>08/02/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Carnegie-Mellon University</Name>
<CityName>PITTSBURGH</CityName>
<ZipCode>152133815</ZipCode>
<PhoneNumber>4122688746</PhoneNumber>
<StreetAddress>5000 Forbes Avenue</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
</Institution>
<ProgramElement>
<Code>7367</Code>
<Text>Cyber-Human Systems (CHS)</Text>
</ProgramElement>
<ProgramReference>
<Code>075Z</Code>
<Text>Artificial Intelligence (AI)</Text>
</ProgramReference>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
</Award>
</rootTag>
