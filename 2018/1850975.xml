<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Doctoral Dissertation Research: An Ethnographic Study of the Making of Mental Health Care Artificial Intelligence</AwardTitle>
<AwardEffectiveDate>03/01/2019</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>11378.00</AwardTotalIntnAmount>
<AwardAmount>11378</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>04040000</Code>
<Directorate>
<Abbreviation>SBE</Abbreviation>
<LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
</Directorate>
<Division>
<Abbreviation>BCS</Abbreviation>
<LongName>Division Of Behavioral and Cognitive Sci</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jeffrey Mantz</SignBlockName>
</ProgramOfficer>
<AbstractNarration>This multi-sited ethnographic investigation will examine how technology companies design artificial intelligence (AI) to provide mental health diagnostic and therapeutic care. What factors guide the many decisions that translate mental health care into algorithms, a set of instructions carried out by AI? There is tremendous variation in how these companies make mental health into an object that is measurable and/or treatable via algorithm. Facial expressions, vocal tone, word choice, or smartphone usage patterns become potential sources of data that communicate mental health states. In other words, companies do not simply collect data; they determine what counts as data sources and establish the correlation of this data to mental health states, and they are doing so in very different ways. In addition to providing funding for the training of a graduate student in anthropology in scientific methods of rigorous data collection and analysis, the project would broadly disseminate its findings to organizations invested in discovering more effective means of improving mental health diagnosis and treatment.&lt;br/&gt;&lt;br/&gt;Valerie Black, under the supervision of Dr. Karen Nakamura at the University of California at Berkeley, will explore how technology companies design AI for mental health diagnosis and treatment. The algorithms developed by companies that gather and analyze mental health data are typically proprietary. Since these algorithms are being developed at a time when AI can determine matters ranging from bank loan eligibility to criminal sentencing, there is a growing call for AI decision-making transparency. This project asks how mental health technology companies in the US and Japan (two major, interconnected centers of AI development) are addressing this concern, and how that impacts the ways in which they use AI to provide care. Research will take place at three AI companies (two in the U.S. and one in Japan) in the understudied startup technology sector. Data collection includes interviews and participant observation with innovators and investors, psychological service leads, and engineers and developers. Data will be analyzed to ascertain what objectives, ethical and practical considerations, and relationships inform the mental health care algorithms. This ethnographic investigation aims to further scientific understanding of how different configurations of and approaches to AI make possible an array of different (and sometimes clashing) objectives, strategies, and core beliefs about what constitutes optimal ways of caring for mental health. The project will advance theoretical understanding at the intersections of anthropology, psychology, and STS around datafication in health care and how mental care, as experienced across different cultural terrains, is translated into algorithms.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>02/26/2019</MinAmdLetterDate>
<MaxAmdLetterDate>02/26/2019</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1850975</AwardID>
<Investigator>
<FirstName>Karen</FirstName>
<LastName>Nakamura</LastName>
<EmailAddress>karen.nakamura@berkeley.edu</EmailAddress>
<StartDate>02/26/2019</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Valerie</FirstName>
<LastName>Black</LastName>
<EmailAddress>vblack@berkeley.edu</EmailAddress>
<StartDate>02/26/2019</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of California-Berkeley</Name>
<CityName>BERKELEY</CityName>
<ZipCode>947101749</ZipCode>
<PhoneNumber>5106433891</PhoneNumber>
<StreetAddress>Sponsored Projects Office</StreetAddress>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
</Institution>
<ProgramElement>
<Code>7605</Code>
<Text>DDRI Cult Anthro</Text>
</ProgramElement>
<ProgramReference>
<Code>063Z</Code>
<Text>W-HTF Work at the Human-Technology Front</Text>
</ProgramReference>
<ProgramReference>
<Code>1390</Code>
<Text>CULTURAL ANTHROPOLOGY</Text>
</ProgramReference>
<ProgramReference>
<Code>9179</Code>
<Text>GRADUATE INVOLVEMENT</Text>
</ProgramReference>
</Award>
</rootTag>
