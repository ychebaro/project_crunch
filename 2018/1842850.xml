<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SBIR Phase I:  Filmmaking for Everyone: Computational Video Editing</AwardTitle>
<AwardEffectiveDate>01/01/2019</AwardEffectiveDate>
<AwardExpirationDate>06/30/2019</AwardExpirationDate>
<AwardAmount>224734</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07070000</Code>
<Directorate>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Peter Atherton</SignBlockName>
</ProgramOfficer>
<AbstractNarration>The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project will result from addressing video editing as a software problem. All the hurdles that surround this space - the clunkiness of having to poke at a timeline of clips with your fingers on a rectangle of glass, the time and technical skill required to even know how to put those clips together in a pleasing sequence, and the cost to have someone else do it for you - are all problems that can be solved with computational video editing. The cameras in mobile phones are the most important contemporary tool for artistic expression and cultural communication. The company's mobile video editing platform gives young and economically disadvantaged creators (who may only have a mobile device camera) access to the narrative format of video. With the growing adoption of mobile video by creators and viewers in every corner of the globe, high-quality video editing tools are increasingly needed for mobile platforms.&lt;br/&gt;&lt;br/&gt;This Small Business Innovation Research (SBIR) Phase I project will investigate the use of video understanding techniques that support the creation of artistic and cultural output. This project will develop algorithms, representations, and datasets that allow consumer-grade devices such as smartphones, tablets, and commodity PCs to understand video and generate narrative video sequences. The goal of this Phase I project is at the intersection of human-computer interaction, computer vision, and computational videography. This project will explore rich semantic embedding spaces, end-to-end trained multi-task neural networks, and large-scale data and their application to video manipulation, enhancement, and the ultimate goal of automated film editing.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>12/21/2018</MinAmdLetterDate>
<MaxAmdLetterDate>12/21/2018</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1842850</AwardID>
<Investigator>
<FirstName>Genevieve</FirstName>
<LastName>Patterson</LastName>
<EmailAddress>gen@trash.app</EmailAddress>
<StartDate>12/21/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>TRASH INC.</Name>
<CityName>BROOKLYN</CityName>
<ZipCode>112315113</ZipCode>
<PhoneNumber>5202753170</PhoneNumber>
<StreetAddress>98 4TH ST STE 401</StreetAddress>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
</Institution>
<ProgramElement>
<Code>5371</Code>
<Text>SMALL BUSINESS PHASE I</Text>
</ProgramElement>
<ProgramReference>
<Code>5371</Code>
<Text>SMALL BUSINESS PHASE I</Text>
</ProgramReference>
<ProgramReference>
<Code>8032</Code>
<Text>Software Services and Applications</Text>
</ProgramReference>
</Award>
</rootTag>
