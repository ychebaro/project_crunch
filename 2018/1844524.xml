<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>EAGER: Reconciling Model Discrepancies in Human-Robot Teams</AwardTitle>
<AwardEffectiveDate>09/01/2018</AwardEffectiveDate>
<AwardExpirationDate>08/31/2020</AwardExpirationDate>
<AwardTotalIntnAmount>249929.00</AwardTotalIntnAmount>
<AwardAmount>249929</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Reid Simmons</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Robots greatly complement human capabilities in many domains, but having them function as teammates has often proven to be challenging. This is due in part to a lack of understanding of robots, which often leads humans to find that their expectations of robotic teammates are not met in reality.  The proposed research addresses this by having robots reason about the models people have of them and using those models to either behave in ways that meet the expectations more closely or explain the perceived differences.  The work can have a significant impact on critical domains that involve human-in-the-loop AI systems, such as decision support, automated manufacturing, eldercare, and medical robotics. &lt;br/&gt;&lt;br/&gt;To become reliable teammates, robots must understand the expectations of their human partners regarding the robots' tasks and abilities, and be able to seek reconciliation between the expected and actual models. In this project, reconciliation will be achieved either by 1) biasing the robot's behavior to implicitly accommodate model differences; or 2) communicating to explicitly reduce the differences. The first approach, termed model reconciliation planning, will be formulated as an optimization problem that generates a plan for the robot to execute while minimizing its distance to the expected plan that the human envisions. Heuristic search methods will be developed to accommodate this approach. The second approach will generate explanations to update the human's model of the robot in such a way that the robot's plan more closely matches that of the human's expectation in the updated model.  In addition, machine learning will be used to approximate the model of human expectation when not provided explicitly, and methods for model reconciliation with these learned and incomplete models will be developed.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/13/2018</MinAmdLetterDate>
<MaxAmdLetterDate>08/13/2018</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1844524</AwardID>
<Investigator>
<FirstName>Yu</FirstName>
<LastName>Zhang</LastName>
<EmailAddress>Yu.Zhang.442@asu.edu</EmailAddress>
<StartDate>08/13/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Arizona State University</Name>
<CityName>TEMPE</CityName>
<ZipCode>852816011</ZipCode>
<PhoneNumber>4809655479</PhoneNumber>
<StreetAddress>ORSPA</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Arizona</StateName>
<StateCode>AZ</StateCode>
</Institution>
<ProgramElement>
<Code>8013</Code>
<Text>National Robotics Initiative</Text>
</ProgramElement>
<ProgramReference>
<Code>063Z</Code>
<Text>W-HTF Work at the Human-Technology Front</Text>
</ProgramReference>
<ProgramReference>
<Code>7916</Code>
<Text>EAGER</Text>
</ProgramReference>
<ProgramReference>
<Code>8086</Code>
<Text>Natl Robotics Initiative (NRI)</Text>
</ProgramReference>
</Award>
</rootTag>
