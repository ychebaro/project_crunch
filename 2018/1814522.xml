<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI: Small: Applying discrete reasoning steps in solving natural language processing tasks</AwardTitle>
<AwardEffectiveDate>08/01/2018</AwardEffectiveDate>
<AwardExpirationDate>07/31/2021</AwardExpirationDate>
<AwardAmount>447614</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana D. Korelsky</SignBlockName>
</ProgramOfficer>
<AbstractNarration>Modern natural language processing systems are effective at shallow analysis of unstructured text data, performing tasks such as discovering events, identifying the actors of those events, and grouping events with the same actors. Neural networks help make these systems robust to effects like paraphrasing, but still capture mostly superficial text patterns. To answer deeper questions about things like causal relationships between the events in a text, a system might need to combine several pieces of information, abstract away irrelevant details, and incorporate prior world knowledge to arrive at an answer. This project aims to develop systems that can address these challenges: these systems explicitly model reasoning over text and draw on the power of neural networks to do this reasoning in a nuanced way. Such reasoning is explicitly taught to the systems via "handholding" supervision, which encourages the systems to mimic how humans solve a problem and helps them generalize better to new problem instances. This alignment with what humans do also serves to expose the systems' decision-making processes; it provides a form of explanation of their behavior so that one may evaluate them against desired criteria such as equitability.&lt;br/&gt;&lt;br/&gt;This proposal's technical innovation is focused on two fronts: designing latent variable models and exploiting new types of handholding supervision during model training. These techniques are explored in the context of three challenging problems requiring complex reasoning: (1) solving mathematical word problems; (2) resolving coreference using world knowledge; (3) answering questions from documents. For each problem, new models are proposed centering around discrete derivations of answers, which draw on state-of-the-art tools like attention-based recurrent neural networks to capture the larger context of the reasoning process. The discreteness of the models' decisions provides an anchor to incorporate auxiliary supervision, which is hard to do in fully end-to-end neural models. The nature of the handholding supervision depends on the task and is a combination of incidental supervision, heuristically identified derivations, and targeted human annotation. Each of the addressed problems tests different aspects of the approach, such as handling complex derivations and incorporating world knowledge, and these problems yield concrete evaluation frameworks to understand the efficacy of the proposed techniques.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>07/25/2018</MinAmdLetterDate>
<MaxAmdLetterDate>07/25/2018</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1814522</AwardID>
<Investigator>
<FirstName>Gregory</FirstName>
<LastName>Durrett</LastName>
<EmailAddress>gdurrett@cs.utexas.edu</EmailAddress>
<StartDate>07/25/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at Austin</Name>
<CityName>Austin</CityName>
<ZipCode>787595316</ZipCode>
<PhoneNumber>5124716424</PhoneNumber>
<StreetAddress>3925 W Braker Lane, Ste 3.340</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
</Institution>
<ProgramElement>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramElement>
<ProgramReference>
<Code>075Z</Code>
<Text>Artificial Intelligence (AI)</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
</Award>
</rootTag>
