<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>Understanding Pedestrian Dynamics for Seamless Human-Robot Interaction</AwardTitle>
<AwardEffectiveDate>09/01/2018</AwardEffectiveDate>
<AwardExpirationDate>08/31/2021</AwardExpirationDate>
<AwardAmount>358535</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07030000</Code>
<Directorate>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<LongName>Div Of Civil, Mechanical, &amp; Manufact Inn</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Robert Scheidt</SignBlockName>
</ProgramOfficer>
<AbstractNarration>In the near future, robots will navigate alongside people in busy, crowded and unconstrained environments such as shopping malls, airports and elder-care facilities. Current mobile robot motion planners are inadequate because current models of pedestrian dynamics do not fully capture the complexity of human motion behavior in crowds. As a result, robots can "freeze" in places where crowd density is high, which further impedes pedestrian traffic flow. This project will use novel machine learning techniques to develop a robot motion planner with human-like navigations features. The project team will use objective and subjective performance measures to evaluate the predictability and acceptability of human-robot interactions with robots and their novel control algorithms deployed in shopping malls and campus buildings. This project serves the national interest because the resulting pedestrian dynamics modeling methods and robot controllers may result in public safety applications such as emergency evacuations and crowd planning/management. The project will involve an educational component that provides engineering and research methods training to graduate and undergraduate students, as well as STEM outreach to high-school and middle-school students. Additional efforts will be made to attract and retain women into careers in science and engineering. &lt;br/&gt;&lt;br/&gt;This research investigates new control methodologies that promise improved pedestrian/mobile-robot navigation through crowded and unconstrained environments. Methods include the extraction of features related to pedestrian behavior from existing datasets and their use in training a deep neural network (DNN) to model pedestrian dynamics; the use of inverse reinforcement learning to generate a cost map that humans follow to navigate; the implementation of the map within a robot motion controller; and the experimental testing and validation of the controller in real-world human environments using objective and subjective performance criteria.  The experimental and evaluation data will be made available for use by the research community.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/22/2018</MinAmdLetterDate>
<MaxAmdLetterDate>08/22/2018</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1825709</AwardID>
<Investigator>
<FirstName>Yi</FirstName>
<LastName>Guo</LastName>
<EmailAddress>yguo1@stevens.edu</EmailAddress>
<StartDate>08/22/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Stevens Institute of Technology</Name>
<CityName>HOBOKEN</CityName>
<ZipCode>070305991</ZipCode>
<PhoneNumber>2012168762</PhoneNumber>
<StreetAddress>CASTLE POINT ON HUDSON</StreetAddress>
<CountryName>United States</CountryName>
<StateName>New Jersey</StateName>
<StateCode>NJ</StateCode>
</Institution>
<ProgramElement>
<Code>004Y</Code>
<Text>Science of Learning</Text>
</ProgramElement>
<ProgramElement>
<Code>058Y</Code>
<Text>M3X - Mind, Machine, and Motor</Text>
</ProgramElement>
<ProgramReference>
<Code>059Z</Code>
<Text>Science of Learning</Text>
</ProgramReference>
<ProgramReference>
<Code>063Z</Code>
<Text>W-HTF Work at the Human-Technology Front</Text>
</ProgramReference>
<ProgramReference>
<Code>070E</Code>
<Text>INTEG OF HUMAN &amp; COGNITIVE</Text>
</ProgramReference>
<ProgramReference>
<Code>6856</Code>
<Text>ARTIFICIAL INTELL &amp; COGNIT SCI</Text>
</ProgramReference>
<ProgramReference>
<Code>7632</Code>
<Text>HUMAN-ROBOT INTERACTION</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
</Award>
</rootTag>
