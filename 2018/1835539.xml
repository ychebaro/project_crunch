<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CRII: RI: Multi-Source Domain Generalization Approaches to Visual Attribute Detection</AwardTitle>
<AwardEffectiveDate>12/23/2017</AwardEffectiveDate>
<AwardExpirationDate>04/30/2020</AwardExpirationDate>
<AwardTotalIntnAmount>40778.00</AwardTotalIntnAmount>
<AwardAmount>40778</AwardAmount>
<AwardInstrument>
<Value>Continuing grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
</ProgramOfficer>
<AbstractNarration>This project investigates how to accurately and robustly detect attributes from images (videos, and 3D data), with the goal of developing and publicly providing effective attribute detection tools. Visual attributes refer to human-namable and machine-detectable inherent characteristics of visual content from objects, scenes, and activities (e.g., four-legged, outdoor, and crowded). They possess versatile properties and application potentials by offering a natural human-computer interaction channel for involving humans in the loop of machine vision algorithms, serving as basic building blocks for one to compose categories and describe instances, and bringing rich prior knowledge and regularization to statistical learning models, to name a few. The project advances the long-standing pursuit of utilizing attributes for a wide variety of visual recognition and search tasks. The project also actively engages graduate and undergraduate students, and outreaches local high-school students. The research results from this project can impact several related communities such as NLP, speech, and robotics, etc.. &lt;br/&gt; &lt;br/&gt;This research explicitly tackles the need that attribute detectors should generalize well across different categories, including those previously unseen ones. The research team approaches the problem based on multi-source domain generalization by taking each category as a domain. In particular, this project develops new feature extraction tools tailored to account for the middle-level attributes, as opposed to the traditional features primarily designed and tested for high-level visual recognition. The project consists of three major thrusts hinging on the key motivation of the analogy between attribute detection and domain generalization. It begins by learning a fine-grained "shallow" feature mapping (Thrust I) to distill attribute-discriminative signals that are category-invariant, and then investigates "deeper" into the feature extraction frameworks - Fisher vectors (Thrust II) and convolutional neural networks (Thrust III)-to revise them for the purpose of attribute detection.</AbstractNarration>
<MinAmdLetterDate>06/11/2018</MinAmdLetterDate>
<MaxAmdLetterDate>06/11/2018</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>1835539</AwardID>
<Investigator>
<FirstName>Boqing</FirstName>
<LastName>Gong</LastName>
<EmailAddress>bgong@icsi.berkeley.edu</EmailAddress>
<StartDate>06/11/2018</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>International Computer Science Institute</Name>
<CityName>Berkeley</CityName>
<ZipCode>947044115</ZipCode>
<PhoneNumber>5106662900</PhoneNumber>
<StreetAddress>1947 CENTER ST STE 600</StreetAddress>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
</Institution>
<ProgramElement>
<Code>026Y</Code>
<Text>CRII CISE Research Initiation</Text>
</ProgramElement>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>8228</Code>
<Text>CISE Resrch Initiatn Initiatve</Text>
</ProgramReference>
</Award>
</rootTag>
